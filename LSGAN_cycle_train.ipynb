{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle-GAN code for spectrogram-to-spectrogram translation\n",
    "# Credit to https://github.com/aitorzip/PyTorch-CycleGAN\n",
    "\n",
    "import argparse\n",
    "import itertools\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import torch\n",
    "from models import Generator\n",
    "from models import Discriminator\n",
    "from utils import ReplayBuffer\n",
    "from utils import LambdaLR\n",
    "from utils import Logger\n",
    "from utils import weights_init_normal\n",
    "from datasets import ImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--epoch', type=int, default=0)\n",
    "parser.add_argument('--n_epochs', type=int, default=150)\n",
    "parser.add_argument('--batchSize', type=int, default=1)\n",
    "parser.add_argument('--dataroot', type=str, default='media/Mohammad/allSpectrograms/')\n",
    "parser.add_argument('--lr', type=float, default=0.0002)\n",
    "parser.add_argument('--decay_epoch', type=int, default=250)\n",
    "parser.add_argument('--size', type=int, default=256)\n",
    "parser.add_argument('--input_nc', type=int, default=3)\n",
    "parser.add_argument('--output_nc', type=int, default=3)\n",
    "parser.add_argument('--cuda', action='store_true')\n",
    "opt = parser.parse_args()\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generators and Discriminator definition\n",
    "# F_ST: Generator to map from Source to Target\n",
    "# F_TS: Generator to map from Target to Source\n",
    "# D_S: Discriminator for F_ST\n",
    "# D_T: Discriminator for F_TS\n",
    "\n",
    "\"\"\"\n",
    "D_S and D_T are the same!\n",
    "\"\"\"\n",
    "\n",
    "F_ST = Generator(opt.input_nc, opt.output_nc)\n",
    "F_TS = Generator(opt.output_nc, opt.input_nc)\n",
    "D_S = Discriminator(opt.input_nc)\n",
    "D_T = Discriminator(opt.output_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA Setups for Generators and Discriminator\n",
    "if opt.cuda:\n",
    "    F_ST.cuda()\n",
    "    F_TS.cuda()\n",
    "    D_S.cuda()\n",
    "    D_T.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "# call random step function \n",
    "F_ST.apply(weights_init_normal)\n",
    "F_TS.apply(weights_init_normal)\n",
    "D_S.apply(weights_init_normal)\n",
    "D_T.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss metrics and optimizers\n",
    "\n",
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_cycle = torch.nn.L1Loss()\n",
    "criterion_identity = torch.nn.L1Loss()\n",
    "\n",
    "# Optimizers and lr schedulers\n",
    "optimizer_F = torch.optim.Adam(itertools.chain(F_ST.parameters(),\n",
    "                                               F_TS.parameters()),\n",
    "                               lr=opt.lr, betas=(0.35, 0.999))\n",
    "optimizer_D_S = torch.optim.Adam(D_S.parameters(),\n",
    "                                 lr=opt.lr,\n",
    "                                 betas=(0.35, 0.999))\n",
    "optimizer_D_T = torch.optim.Adam(D_T.parameters(),\n",
    "                                 lr=opt.lr,\n",
    "                                 betas=(0.35, 0.999))\n",
    "\n",
    "lr_scheduler_F = torch.optim.lr_scheduler.LambdaLR(optimizer_F, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step)\n",
    "lr_scheduler_D_S = torch.optim.lr_scheduler.LambdaLR(optimizer_D_S, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step)\n",
    "lr_scheduler_D_T = torch.optim.lr_scheduler.LambdaLR(optimizer_D_T, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input loading\n",
    "# call loader command herein\n",
    "\n",
    "# Setting hyperparameters\n",
    "# Note to call random search alg. (Optional)\n",
    "# change for datasets\n",
    "mu = 0.12\n",
    "sigma = 0.58\n",
    "c1 = 0.39\n",
    "c2 = 0.68\n",
    "alpha = 0.19\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if opt.cuda else torch.Tensor\n",
    "input_S= Tensor(opt.batchSize, opt.input_nc, opt.size, opt.size)\n",
    "input_T = Tensor(opt.batchSize, opt.output_nc, opt.size, opt.size)\n",
    "out_T_real = Variable(Tensor(opt.batchSize).fill_(1.0), requires_grad=False)\n",
    "out_T_fake = Variable(Tensor(opt.batchSize).fill_(0.0), requires_grad=False)\n",
    "fake_S_buffer = ReplayBuffer()\n",
    "fake_T_buffer = ReplayBuffer()\n",
    "\n",
    "transforms_ = [transforms.Resize(int(opt.size*1.08), \n",
    "                                 Image.BICUBIC),\n",
    "               transforms.RandomCrop(opt.size), \n",
    "               transforms.RandomHorizontalFlip(),\n",
    "               transforms.ToTensor(),\n",
    "               transforms.Normalize((0.4,0.4,0.4), (0.4,0.4,0.4))]\n",
    "dataloader = DataLoader(ImageDataset(opt.dataroot, transforms_=transforms_, unaligned=True), \n",
    "                        batch_size=opt.batchSize, shuffle=True, num_workers=opt.n_cpu)\n",
    "logger = Logger(opt.n_epochs, len(dataloader))\n",
    "\n",
    "for epoch in range(opt.epoch, opt.n_epochs):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        # S: Source\n",
    "        # T: Target\n",
    "        real_S = Variable(input_A.copy_(batch['S']))\n",
    "        real_T = Variable(input_T.copy_(batch['T']))\n",
    "        optimizer_F.zero_grad()\n",
    "        same_T = F_ST(real_T)*c1\n",
    "        loss_identity_T = criterion_identity(same_T, real_T)*mu\n",
    "        same_S = F_TS(real_S)*c2\n",
    "        loss_identity_S = criterion_identity(same_S, real_S)*sigma\n",
    "        fake_T = F_ST(real_S)\n",
    "        pred_fake = D_T(fake_T)\n",
    "        loss_GAN_S_to_T = criterion_GAN(pred_fake, out_T_real)\n",
    "        fake_S = F_TS(real_T)\n",
    "        pred_fake = D_S(fake_S)\n",
    "        loss_GAN_T_to_S = criterion_GAN(pred_fake, out_T_real)\n",
    "        recovered_S = F_TS(fake_T)\n",
    "        loss_cycle_STS= criterion_cycle(recovered_S, real_S)*alpha\n",
    "        recovered_T = F_ST(fake_S)\n",
    "        loss_cycle_TST = criterion_cycle(recovered_T, real_T)*alpha\n",
    "        loss_F = loss_identity_S + loss_identity_T + loss_GAN_S_to_T +\n",
    "                loss_GAN_T_to_S + loss_cycle_STS+ loss_cycle_TST\n",
    "        loss_F.backward()\n",
    "        optimizer_F.step()\n",
    "        optimizer_D_S.zero_grad()\n",
    "        pred_real = D_S(real_S)\n",
    "        loss_D_real = criterion_GAN(pred_real, out_T_real)\n",
    "        fake_S = fake_S_buffer.push_and_pop(fake_S)\n",
    "        pred_fake = D_S(fake_S.detach())\n",
    "        loss_D_fake = criterion_GAN(pred_fake, out_T_fake)\n",
    "        loss_D_S = (loss_D_real + loss_D_fake)*0.5\n",
    "        loss_D_S.backward()\n",
    "        optimizer_D_S.step()\n",
    "        optimizer_D_T.zero_grad()\n",
    "        pred_real = D_T(real_T)\n",
    "        loss_D_real = criterion_GAN(pred_real, out_T_real)\n",
    "        fake_T = fake_T_buffer.push_and_pop(fake_T)\n",
    "        pred_fake = D_T(fake_T.detach())\n",
    "        loss_D_fake = criterion_GAN(pred_fake, out_T_fake)\n",
    "        loss_D_T= (loss_D_real + loss_D_fake)*0.5\n",
    "        loss_D_T.backward()\n",
    "        optimizer_D_T.step()\n",
    "        \n",
    "        # Logger report\n",
    "        logger.log({'loss_F': loss_F, 'loss_F_identity': (loss_identity_S + loss_identity_T),\n",
    "                    'loss_F_GAN': (loss_GAN_S_to_T + loss_GAN_T_to_S),\n",
    "                    'loss_F_cycle': (loss_cycle_STS+ loss_cycle_TST), 'loss_D': (loss_D_S + loss_D_T)}, \n",
    "                    images={'real_S': real_S, 'real_T': real_T, 'fake_S': fake_S, 'fake_T': fake_T})\n",
    "\n",
    "    lr_scheduler_F.step()\n",
    "    lr_scheduler_D_S.step()\n",
    "    lr_scheduler_D_T.step()\n",
    "\n",
    "    torch.save(F_ST.state_dict(), 'output/local/tmp/F_ST.pth')\n",
    "    torch.save(D_S.state_dict(), 'output/local/tmp/D_S.pth')\n",
    "    torch.save(F_TS.state_dict(), 'output/local/tmp/F_TS.pth')\n",
    "    torch.save(D_T.state_dict(), 'output/local/tmp/D_T.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
